{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "STUDENT_Lab_3_Part_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h6Gp-H2w_w0"
      },
      "source": [
        "# Lab 3 (Part 1): Convolutional NNs for CIFAR 10\n",
        "\n",
        "\n",
        "------------------------------------------------------\n",
        "*Neural Networks. Bachelor in Data Science and Engineering*\n",
        "\n",
        "*Pablo M. Olmos pamartin@ing.uc3m.es*\n",
        "\n",
        "*Aurora Cobo Aguilera acobo@tsc.uc3m.es*\n",
        "\n",
        "------------------------------------------------------\n",
        "\n",
        "\n",
        "In this third part of the lab, we will use a data set of (small) natural images known as  [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html). Our goal is to present i) how CNN layers are used in Pytorch, and ii) evaluate the performance of a simple CNN over this dataset.\n",
        "\n",
        "Note: a big part of the following material is a personal wrap-up of [Facebook's Deep Learning Course in Udacity](https://www.udacity.com/course/deep-learning-pytorch--ud188). So all credit goes for them!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N64O8m1lxTbr"
      },
      "source": [
        "**IMPORTANT NOTE:** In this notebook I show you how to speed up NN training using Graphical Processing Units (GPUs). To make sure you use a Google Colaboratory server equipped with a GPU, go to `Edit` --> `Notebook Settings` --> Select GPU in `Hardware Accelerator`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBOU3HVIw_w2"
      },
      "source": [
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "\n",
        "Image(url= \"https://pytorch.org/tutorials/_images/cifar10.png\", width=400, height=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUkbs61ww_xD"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'  #To get figures with high quality!\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaz7dyClw_xO"
      },
      "source": [
        "## Part I. Download CIFAR10 with `torchvision`\n",
        "\n",
        "The code below will download the CIFAR10 dataset, then create training and test datasets for us. It is mostly the same code we used to download MNIST in the previous part of the Lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI9c0Qr6w_xP"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, utils\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO2pJitSw_xY"
      },
      "source": [
        "traindata = iter(trainloader)\n",
        "\n",
        "images, labels = next(traindata)\n",
        "\n",
        "print(images[1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpmTUwjAAYA8"
      },
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize to pot\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKs8e3Wx_Ayp"
      },
      "source": [
        "imshow(utils.make_grid(images))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoadX1VGw_xq"
      },
      "source": [
        "> **Exercise:** Create a validation set using the 20% of train images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kamncjp2w_xr"
      },
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEZKYwuFw_xy"
      },
      "source": [
        "## Part II. Implement Lenet 5\n",
        "\n",
        "Our first goal is to implement the LeNet 5 CNN network, first published in November 1998. See the original paper [here](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMp7MGqtw_xz"
      },
      "source": [
        "Image(url= \"https://engmrk.com/wp-content/uploads/2018/09/LeNet_Original_Image.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3-BUzM3w_x5"
      },
      "source": [
        "In the CNN network above we have 2 convolutional layers with the following properties:\n",
        "\n",
        "- ReLU activation functions are used as non-linear functions\n",
        "- Maxpooling with $2\\times 2$ kernels is used to reduce the spatial dimension in both layers.\n",
        "- $5\\times 5$ convolutional filters are used. Stride is 1.\n",
        "- After the second convolutional layer, three dense layers are stacked. \n",
        "\n",
        "Note that CIFAR-10 images are composed by **3 input color maps**, each of dimension $32\\times32$.\n",
        "\n",
        "> **Exercise:** Complete the following code that defines the above CNN. But first read the [`torch.nn.Conv2d`](https://pytorch.org/docs/stable/nn.html) documentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I24Pru6mw_x7"
      },
      "source": [
        "class Lenet5(nn.Module):\n",
        "    def __init__(self,dimx,nlabels): #Nlabels will be 10 in our case\n",
        "        super().__init__()\n",
        "\n",
        "        # convolutional layer (sees 28x28x1 image tensor)\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, \n",
        "                               kernel_size=5, stride=1, padding=0)\n",
        "        \n",
        "        # convolutional layer (sees 12x12x16 tensor)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, padding=0)\n",
        "        \n",
        "        # Max pool layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Linear layers\n",
        "        self.linear1 = #YOUR CODE HERE\n",
        "        \n",
        "        self.linear2 = #YOUR CODE HERE\n",
        "        \n",
        "        self.linear3 = #YOUR CODE HERE\n",
        "    \n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1) \n",
        "        \n",
        "        # Spatial dimension of the Tensor at the output of the 2nd CNN\n",
        "        self.final_dim = int(((dimx-4)/2-4)/2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Pass the input tensor through the CNN operations\n",
        "        x = self.conv1(x) #YOUR CODE HERE\n",
        "        x = self.relu(x) \n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        # Flatten the tensor into a vector of appropiate dimension using self.final_dim\n",
        "        x = x.view(#YOUR CODE HERE)\n",
        "        # Pass the tensor through the Dense Layers\n",
        "        x = #YOUR CODE HERE\n",
        "        x = #YOUR CODE HERE\n",
        "        x = #YOUR CODE HERE\n",
        "        x = #YOUR CODE HERE\n",
        "        x = #YOUR CODE HERE\n",
        "        x = self.logsoftmax(x) \n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwAOgRCw_yB"
      },
      "source": [
        "Now the network is defined, by now you should know how to move forward by your own!!\n",
        "\n",
        "> **Exercise:** Extend the class to incorporate a training method, to evaluate the both the validation and train losses and to evaluate the classification performance in a set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M7bRorkw_yC"
      },
      "source": [
        "#YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZh-0Ybrw_yI"
      },
      "source": [
        "> **Exercise:** Train the model for 5 epochs, plot the train/validation loss during training, and compute the train and validation performance. It will take some time!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLCw4i_Gw_yK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0461a995-2b4a-4071-cf4f-58fbd6be7f59"
      },
      "source": [
        "my_CNN = #YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0. Training loss: 1.657804, Validation loss: 1.456827, Time per epoch: 16.280600 seconds\n",
            "Epoch 1. Training loss: 1.383154, Validation loss: 1.305181, Time per epoch: 15.574760 seconds\n",
            "Epoch 2. Training loss: 1.263761, Validation loss: 1.215136, Time per epoch: 15.299289 seconds\n",
            "Epoch 3. Training loss: 1.184578, Validation loss: 1.175317, Time per epoch: 15.255599 seconds\n",
            "Epoch 4. Training loss: 1.119563, Validation loss: 1.158535, Time per epoch: 14.837524 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uCdY1BLw_yZ"
      },
      "source": [
        "## Part III. GPU-based training\n",
        "\n",
        "As you noticed, training became excessively slow. The newtork is already quite deep and gradient evaluation becomes a heavy operation. \n",
        "\n",
        "PyTorch, along with pretty much every other deep learning framework, uses [CUDA](https://developer.nvidia.com/cuda-zone) to efficiently compute the forward and backwards passes on the GPU. In PyTorch, you move your model parameters and other tensors to the GPU memory using `model.to('cuda')`. You can move them back from the GPU with `model.to('cpu')` which you'll commonly do when you need to operate on the network output outside of PyTorch. As a demonstration of the increased speed, I'll compare how long it takes to perform a forward and backward pass with and without a GPU.\n",
        "\n",
        "You can write device agnostic code which will automatically use CUDA if it's enabled like so:\n",
        "```python\n",
        "# at beginning of the script\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "...\n",
        "\n",
        "# then whenever you get a new Tensor or Module\n",
        "# this won't copy if they are already on the desired device\n",
        "input = data.to(device)\n",
        "model = MyModule(...).to(device)\n",
        "```\n",
        "\n",
        "> **Exercise:** Complete the following class, which implements the CNN training and validation using a GPU (if possible). \n",
        "\n",
        "**Note: Google Colab Recommended**. When running the notebook in Google Colab, make sure you first to `Edit -- Notebook settings` and **select a GPU as Hardware accelerator.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCMInLLPw_ya"
      },
      "source": [
        "class Lenet5_extended_GPU(Lenet5):\n",
        "    \n",
        "    #Your code here\n",
        "    \n",
        "    def __init__(self,dimx,nlabels,epochs=100,lr=0.001):\n",
        "        \n",
        "        super().__init__(dimx,nlabels)  \n",
        "        \n",
        "        self.lr = lr #Learning Rate\n",
        "        \n",
        "        self.optim = optim.Adam(self.parameters(), self.lr)\n",
        "        \n",
        "        self.epochs = epochs\n",
        "        \n",
        "        self.criterion = nn.NLLLoss()             \n",
        "        \n",
        "        # A list to store the loss evolution along training\n",
        "        \n",
        "        self.loss_during_training = [] \n",
        "        \n",
        "        self.valid_loss_during_training = []\n",
        "        \n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.to(self.device)\n",
        "        \n",
        "    def trainloop(self,trainloader,validloader):\n",
        "        \n",
        "        # Optimization Loop\n",
        "        \n",
        "        for e in range(int(self.epochs)):\n",
        "            \n",
        "            start_time = time.time()\n",
        "            \n",
        "            # Random data permutation at each epoch\n",
        "            \n",
        "            running_loss = 0.\n",
        "            \n",
        "            for images, labels in trainloader:\n",
        "                \n",
        "                # Move input and label tensors to the default device\n",
        "                images, labels = images.to(self.device), labels.to(self.device)  \n",
        "        \n",
        "                #Reset Gradients!\n",
        "                #YOUR CODE HERE\n",
        "            \n",
        "                out = self.forward(images)\n",
        "\n",
        "                #Your code here\n",
        "                loss = self.criterion(out,labels)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                #Compute gradients\n",
        "                #YOUR CODE HERE\n",
        "                \n",
        "                #SGD stem\n",
        "                #YOUR CODE HERE\n",
        "                \n",
        "                \n",
        "            self.loss_during_training.append(running_loss/len(trainloader))\n",
        "            \n",
        "            # Validation Loss\n",
        "            \n",
        "            # Turn off gradients for validation, saves memory and computations\n",
        "            with torch.no_grad():            \n",
        "                \n",
        "                running_loss = 0.\n",
        "                \n",
        "                for images,labels in validloader:\n",
        "                    \n",
        "                    # Move input and label tensors to the default device\n",
        "                    images, labels = #YOUR CODE HERE                    \n",
        "                    \n",
        "                    # Compute output for input minibatch\n",
        "                    out = #YOUR CODE HERE\n",
        "\n",
        "                    #Your code here\n",
        "                    loss = #YOUR CODE HERE\n",
        "\n",
        "                    running_loss += loss.item()   \n",
        "                    \n",
        "                self.valid_loss_during_training.append(running_loss/len(validloader))    \n",
        "                    \n",
        "\n",
        "            if(e % 1 == 0): # Every epoch\n",
        "\n",
        "                print(\"Epoch %d. Training loss: %f, Validation loss: %f, Time per epoch: %f seconds\" \n",
        "                      %(e,self.loss_during_training[-1],self.valid_loss_during_training[-1],\n",
        "                       (time.time() - start_time)))\n",
        "                \n",
        "    def eval_performance(self,dataloader):\n",
        "        \n",
        "        loss = 0\n",
        "        accuracy = 0\n",
        "\n",
        "        # Turn off gradients for validation, saves memory and computations\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for images,labels in dataloader:\n",
        "                # Move input and label tensors to the default device\n",
        "                images, labels = #YOUR CODE HERE \n",
        "                probs = #YOUR CODE HERE\n",
        "\n",
        "                top_p, top_class = probs.topk(1, dim=1)\n",
        "                equals = (top_class == labels.view(images.shape[0], 1))\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "    \n",
        "            return accuracy/len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LRYT2MQw_yh"
      },
      "source": [
        "my_CNN_GPU = Lenet5_extended_GPU(dimx=32,nlabels=10,epochs=5,lr=1e-3)\n",
        "\n",
        "my_CNN_GPU.trainloop(trainloader,validloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlSIYZXgw_yo"
      },
      "source": [
        "plt.plot(my_CNN_GPU.loss_during_training,label='Training Loss')\n",
        "plt.plot(my_CNN_GPU.valid_loss_during_training,label='Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "print(my_CNN_GPU.eval_performance(trainloader))\n",
        "print(my_CNN_GPU.eval_performance(validloader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jqxtZrkw_yt"
      },
      "source": [
        "With a GPU, you will see that the time per epoch roughly decreases significantly. As we train deeper and much more complex networks, **this difference grows exponentially fast**. Using GPUs is a must for lage-scale deployment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgf9w1eBw_yv"
      },
      "source": [
        "## Part IV. Regularize the network and compare with a MLP\n",
        "\n",
        "> **Exercise**: Now that you know how to train the CNN network, your goals are:\n",
        "> - Check that the CNN is able to overfit\n",
        "> - Regularize the network with both early stopping and dropout. In my experience, it is more efficient to include the dropout layers in between the final MLP layers, rather than in between convolutional layers. Note that once you include dropout, it wil take more epochs to converge. The more dropout layers, the more epochs typically you have to run. For this exercise, run at least 50 epochs.\n",
        "> - Check the train/validation/test performance, plot the train and validation losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETMGgPQxJ_rB"
      },
      "source": [
        "#YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP-TA_lAGgFH"
      },
      "source": [
        "### Train an MLP to compare the performance (Optional)\n",
        "\n",
        "Train an MLP with 3-4 layers to compare the performance. Take into account that the input image has three color maps. If you stuck it into a vector, then the input dimension is 3x32x32 = 3072. An alternative is to compute the average between the three. Alternatively, you could use only one color map, or the average between three of them ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDjePUsZH0Ut"
      },
      "source": [
        "#YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}